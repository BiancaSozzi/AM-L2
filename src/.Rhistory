shiny::runApp('D:/UTN/AM/Presentación')
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
setwd("D:/UTN/AM/AM-L2/src")
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
set.seed(1)
datap <- 10
## Read dataset
data <- read.dataset("../data/faces.csv")
data <- data[1:datap,] # estoy limitando el entrenamiento a 10 ejemplos
## Split for train and test sets
splits <- split.data(data, 0.3)
train.set <- splits$train
test.set <- splits$test
## bp: modelo de red neuronal aprendido usando backpropagation
## La funciÃ³n puede demorarse al correr. Para depurar los errores de programaciÃ³n,
## ejecute backprop con un conjunto chico de train.set y max.iter < 20.
bp <- backprop(train.set[],formula = class ~ .,eta=0.05, n.out = 4, n.hidden = 3, eps=1e-3, max.iter=10)
bp <- backprop(train.set[],formula = class ~ .,eta=0.05, n.out = 4, n.hidden = 3, eps=1e-3, max.iter=10)
backprop(train.set[],formula = class ~ .,eta=0.05, n.out=4, n.hidden=3, eps=1e-3, max.iter=10)
backprop(train.set[],formula = class~.,eta=0.05, n.out=4, n.hidden=3, eps=1e-3, max.iter=10)
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
backprop(train.set[],formula = class~.,eta=0.05, n.out=4, n.hidden=3, eps=1e-3, max.iter=10)
backprop(train.set[],formula = class~.,eta=0.05, n.out=4, n.hidden=3, eps=1e-3, max.iter=15)
backprop(train.set[],formula = class~.,eta=0.05, n.out=4, n.hidden=3, eps=1e-3, max.iter=20)
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
backprop(train.set[],formula = class~.,eta=0.05, n.out=4, n.hidden=3, eps=1e-3, max.iter=30)
bp
bp <- backprop(train.set[],formula = class~.,eta=0.05, n.out=4, n.hidden=3, eps=1e-3, max.iter=10)
bp
library(ggplot2)
ggplot(data= bp$errors, aes(x=bp$errors, y=bp$errors, fill="red"))
+ geom_bar(stat="identity")
+ ggtitle("Errores por iteración")
+ labs(x="Iteración", y ="Error")
ggplot(data= bp$errors, aes(x=bp$errors, y=bp$errors, fill="blue"))
ggplot(data= bp, aes(x=bp$errors, y=bp$errors, fill="blue"))
ggplot(data= as.matrix(bp$errors), aes(x=bp$errors, y=bp$errors, fill="blue"))
ggplot(data= bp, aes(x=bp$errors, y=bp$errors, fill="blue"))
plot(1:bp$iters, bp$errors, type="l")
plot(1:bp$iters, bp$errors, type="l")
bp
plot(1:bp$iters, bp$errors, type="l")
bp$errors
bp <- backprop(train.set[],formula = class~.,eta=0.05, n.out=4, n.hidden=3, eps=1e-3, max.iter=10)
bp
length(bp$errors)
plot(1:bp$iters, bp$errors[-1], type="l")
bp$errors[-1]
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment
run.backpropagation.experiment()
plot(1:bp$iters, bp$errors[-1], type="l")
set.seed(1)
datap <- 10
## Read dataset
data <- read.dataset("../data/faces.csv")
data <- data[1:datap,] # estoy limitando el entrenamiento a 10 ejemplos
## Split for train and test sets
splits <- split.data(data, 0.3)
train.set <- splits$train
test.set <- splits$test
## bp: modelo de red neuronal aprendido usando backpropagation
## La funciÃ³n puede demorarse al correr. Para depurar los errores de programaciÃ³n,
## ejecute backprop con un conjunto chico de train.set y max.iter < 20.
bp <- backprop(train.set[],formula = class~.,eta=0.05, n.out=4, n.hidden=3, eps=1e-3, max.iter=10)
plot(1:bp$iters, bp$errors[-1], type="l")
plot(1:bp$iters, bp$errors[-1], type="l")
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
?plot
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
source('D:/UTN/AM/AM-L2/src/backpropagation.R')
run.backpropagation.experiment()
